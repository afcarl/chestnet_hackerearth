{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chestnet_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(dataset,bs,num_workers,use_gpu):   \n",
    "    \n",
    "    \n",
    "    train_sampler = sampler.SubsetRandomSampler(dataset.tr_idx)\n",
    "    val_sampler = sampler.SubsetRandomSampler(dataset.val_idx)\n",
    "    test_sampler = sampler.SubsetRandomSampler(dataset.test_idx)\n",
    "    small_train_sampler = sampler.SubsetRandomSampler(dataset.sml_tr_idx)\n",
    "    small_val_sampler = sampler.SubsetRandomSampler(dataset.sml_val_idx)\n",
    "\n",
    "\n",
    "    samplers = {\n",
    "        'train':train_sampler,\n",
    "        'val': val_sampler,\n",
    "        'test':test_sampler,\n",
    "        'sml_tr':small_train_sampler,\n",
    "        'sml_val':small_val_sampler\n",
    "    }\n",
    "\n",
    "    dataloaders = {k : DataLoader(dataset,\n",
    "                            batch_size=bs,\n",
    "                            sampler=v,\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=use_gpu\n",
    "                           ) for k,v in samplers.items()}\n",
    "\n",
    "    \n",
    "    return samplers, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_tfms(227)\n",
    "\n",
    "transformed_dataset = XRayDataset(f'{data_folder}train.csv',f'{data_folder}',transform=tfms)\n",
    "\n",
    "use_gpu, num_workers = get_pm_for_dl()\n",
    "\n",
    "samplers, dataloaders = get_dataloaders(transformed_dataset,32,num_workers,use_gpu)\n",
    "dataset_sizes = get_dt_szs(samplers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet34(pretrained=True)\n",
    "for i,param in enumerate(model_ft.parameters()):\n",
    "    if i ==  5:\n",
    "        break\n",
    "    param.requires_grad = False\n",
    "# model_ft.conv1.kernel_size = (3,3)\n",
    "# model_ft.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model_ft.fc = nn.Sequential(nn.Dropout(p=0.5,inplace=True),nn.Linear(2048,14))\n",
    "model_ft = change_to_cuda(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "if train\n",
      "train Loss: 0.0694 Acc: 0.3012\n",
      "else sml_val\n",
      "sml_val Loss: 0.0773 Acc: 0.2929\n",
      "setting best\n",
      "Epoch 1/9\n",
      "----------\n",
      "if train\n",
      "train Loss: 0.0644 Acc: 0.3462\n",
      "else sml_val\n",
      "sml_val Loss: 0.0775 Acc: 0.2429\n",
      "Epoch 2/9\n",
      "----------\n",
      "if train\n",
      "train Loss: 0.0623 Acc: 0.3742\n",
      "else sml_val\n",
      "sml_val Loss: 0.0735 Acc: 0.3214\n",
      "setting best\n",
      "Epoch 3/9\n",
      "----------\n",
      "if train\n"
     ]
    }
   ],
   "source": [
    "model_ft.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_ft.parameters()), lr=1e-4,weight_decay=1)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer_ft, gamma=0.5)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ft, 'min',patience=1,verbose=True)\n",
    "dropout_model,bacc,bwt = train_model(model_ft, criterion, optimizer_ft,scheduler,dataloaders,dataset_sizes,num_epochs=10,data_split=['train','sml_val'],save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sml_val\n",
      "sml_val Loss: 0.0914 Acc: 0.1214\n",
      "[ 0  0 24  0  0 14  0 50  0  0  1 51]\n",
      "[ 3  0  7 12  6  3  3 47  9 18  7 21  3  1]\n"
     ]
    }
   ],
   "source": [
    "pdted,lbs = predict(model_ft,'sml_val',dataloaders,dataset_sizes,criterion)\n",
    "print(np.bincount(pdted))\n",
    "print(np.bincount(lbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_my_root)",
   "language": "python",
   "name": "conda_my_root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
